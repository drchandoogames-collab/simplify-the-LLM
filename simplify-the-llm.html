<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>LLM Universe - Interactive Explainer</title>
  <style>
    @import url("https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;700&family=Fraunces:opsz,wght@9..144,500;9..144,700&display=swap");

    :root {
      --bg-1: #f6efe5;
      --bg-2: #dbeafe;
      --bg-3: #d9f99d;
      --ink: #111827;
      --muted: #4b5563;
      --line: rgba(15, 23, 42, 0.14);
      --card: rgba(255, 255, 255, 0.78);
      --accent: #0f766e;
      --accent-2: #0369a1;
      --chip: #ecfeff;
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      font-family: "Space Grotesk", sans-serif;
      color: var(--ink);
      line-height: 1.5;
      min-height: 100vh;
      background:
        radial-gradient(circle at 8% 6%, var(--bg-3) 0%, transparent 26%),
        radial-gradient(circle at 88% 12%, var(--bg-2) 0%, transparent 28%),
        linear-gradient(160deg, #fff7ed 0%, #f7fee7 45%, #eff6ff 100%);
      overflow-x: hidden;
    }

    body::before,
    body::after {
      content: "";
      position: fixed;
      z-index: -1;
      border-radius: 50%;
      filter: blur(60px);
      opacity: 0.42;
    }

    body::before {
      width: 340px;
      height: 340px;
      background: #67e8f9;
      top: -80px;
      right: -80px;
      animation: driftA 12s ease-in-out infinite;
    }

    body::after {
      width: 320px;
      height: 320px;
      background: #fcd34d;
      left: -70px;
      bottom: -90px;
      animation: driftB 14s ease-in-out infinite;
    }

    @keyframes driftA {
      0%, 100% { transform: translateY(0); }
      50% { transform: translateY(24px); }
    }

    @keyframes driftB {
      0%, 100% { transform: translateX(0); }
      50% { transform: translateX(26px); }
    }

    .wrap {
      width: min(1060px, 92vw);
      margin: 0 auto;
      padding: 24px 0 30px;
    }

    .hero {
      border: 1px solid var(--line);
      border-radius: 26px;
      padding: clamp(20px, 5vw, 38px);
      background: linear-gradient(145deg, rgba(255, 255, 255, 0.86), rgba(255, 255, 255, 0.63));
      backdrop-filter: blur(8px);
      box-shadow: 0 16px 50px rgba(15, 23, 42, 0.1);
      margin-bottom: 16px;
      animation: rise 650ms ease both;
    }

    .eyebrow {
      font-size: 0.8rem;
      letter-spacing: 0.12em;
      text-transform: uppercase;
      color: var(--accent-2);
      font-weight: 700;
      margin: 0;
    }

    h1 {
      font-family: "Fraunces", serif;
      font-size: clamp(1.95rem, 5vw, 3.25rem);
      line-height: 1.04;
      margin: 8px 0 10px;
    }

    .subtitle {
      margin: 0;
      color: var(--muted);
      max-width: 74ch;
    }

    .grid {
      display: grid;
      gap: 14px;
    }

    .card {
      border: 1px solid var(--line);
      border-radius: 20px;
      background: var(--card);
      backdrop-filter: blur(8px);
      padding: 16px;
      box-shadow: 0 7px 24px rgba(0, 0, 0, 0.06);
      animation: rise 620ms ease both;
      animation-delay: calc(var(--i, 0) * 120ms);
    }

    @keyframes rise {
      from {
        opacity: 0;
        transform: translateY(18px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    h2 {
      margin: 4px 0 12px;
      font-size: 1.2rem;
    }

    .flow {
      display: grid;
      gap: 10px;
      grid-template-columns: repeat(auto-fit, minmax(170px, 1fr));
    }

    .step {
      background: #fff;
      border: 1px dashed #9ca3af;
      border-radius: 14px;
      padding: 10px;
      position: relative;
    }

    .step strong {
      color: var(--accent);
      display: block;
      margin-bottom: 3px;
    }

    .tabs {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-bottom: 10px;
    }

    .tab {
      border: 1px solid #94a3b8;
      border-radius: 999px;
      padding: 7px 12px;
      background: #fff;
      font-family: inherit;
      font-weight: 700;
      cursor: pointer;
      transition: all 170ms ease;
    }

    .tab:hover {
      transform: translateY(-1px);
    }

    .tab.active {
      border-color: var(--accent-2);
      background: #dbeafe;
      color: #0c4a6e;
      box-shadow: 0 4px 14px rgba(14, 116, 144, 0.2);
    }

    .panel {
      display: none;
      border: 1px solid var(--line);
      border-radius: 14px;
      padding: 11px;
      background: #fff;
    }

    .panel.active {
      display: block;
      animation: pop 220ms ease;
    }

    @keyframes pop {
      from {
        opacity: 0;
        transform: scale(0.985);
      }
      to {
        opacity: 1;
        transform: scale(1);
      }
    }

    .badge {
      font-size: 0.8rem;
      background: #fef3c7;
      border: 1px solid #fcd34d;
      border-radius: 999px;
      padding: 1px 7px;
      margin-left: 7px;
    }

    .mini {
      color: var(--muted);
      margin: 0 0 10px;
      font-size: 0.96rem;
    }

    .scale {
      border: 1px solid var(--line);
      background: #fff;
      border-radius: 14px;
      padding: 12px;
    }

    .row {
      display: flex;
      gap: 10px;
      align-items: center;
      flex-wrap: wrap;
    }

    input[type="range"] {
      width: min(560px, 100%);
      accent-color: #0f766e;
    }

    .token-box {
      border: 1px solid var(--line);
      border-radius: 14px;
      background: #fff;
      padding: 12px;
    }

    textarea {
      width: 100%;
      min-height: 92px;
      border-radius: 10px;
      border: 1px solid #cbd5e1;
      padding: 10px;
      font-family: inherit;
      font-size: 0.98rem;
      resize: vertical;
    }

    textarea:focus,
    select:focus {
      outline: 2px solid #7dd3fc;
      outline-offset: 1px;
      border-color: #38bdf8;
    }

    select {
      border: 1px solid #cbd5e1;
      border-radius: 9px;
      padding: 7px 10px;
      font-family: inherit;
      font-weight: 600;
      background: #fff;
    }

    .tokens {
      margin-top: 10px;
      display: flex;
      flex-wrap: wrap;
      gap: 7px;
      min-height: 42px;
    }

    .token {
      padding: 4px 8px;
      border: 1px solid #67e8f9;
      border-radius: 999px;
      background: var(--chip);
      font-size: 0.88rem;
      animation: pop 190ms ease;
    }

    .stats {
      margin-top: 8px;
      color: var(--muted);
      font-size: 0.9rem;
    }

    .stack {
      display: grid;
      gap: 10px;
    }

    .chip-grid {
      display: grid;
      gap: 8px;
      grid-template-columns: repeat(auto-fit, minmax(160px, 1fr));
    }

    .chip-card {
      border: 1px solid #cbd5e1;
      border-radius: 10px;
      padding: 8px;
      background: #fff;
      font-size: 0.86rem;
    }

    .chip-card strong {
      display: block;
      color: #075985;
      margin-bottom: 3px;
    }

    .term-tabs {
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      margin-top: 8px;
    }

    .term-tab {
      border: 1px solid #94a3b8;
      border-radius: 999px;
      padding: 5px 10px;
      background: #fff;
      font-family: inherit;
      font-size: 0.78rem;
      font-weight: 700;
      cursor: pointer;
    }

    .term-tab.active {
      border-color: #0284c7;
      background: #dbeafe;
      color: #075985;
    }

    .term-panel {
      display: none;
      margin-top: 8px;
      border: 1px dashed #94a3b8;
      border-radius: 9px;
      padding: 7px;
      background: #f8fafc;
      font-size: 0.82rem;
    }

    .term-panel.active {
      display: block;
    }

    .pill-row {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-top: 10px;
    }

    .pill {
      border: 1px solid #99f6e4;
      background: #f0fdfa;
      border-radius: 999px;
      padding: 5px 10px;
      font-size: 0.86rem;
      cursor: pointer;
      font-weight: 600;
    }

    .pill.active {
      border-color: #0e7490;
      background: #cffafe;
      color: #164e63;
    }

    .flow-mini {
      display: grid;
      gap: 8px;
      grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
      margin-top: 10px;
    }

    .vector-grid {
      display: grid;
      gap: 8px;
      grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
      margin-top: 8px;
    }

    .vector-box {
      border: 1px solid #cbd5e1;
      background: #fff;
      border-radius: 10px;
      padding: 9px;
      font-size: 0.9rem;
    }

    .attn-inputs {
      display: flex;
      gap: 8px;
      flex-wrap: wrap;
      align-items: center;
      margin-bottom: 8px;
    }

    .attn-bars {
      display: grid;
      gap: 8px;
    }

    .bar-row {
      display: grid;
      grid-template-columns: 130px 1fr 54px;
      gap: 8px;
      align-items: center;
      font-size: 0.9rem;
    }

    .bar-track {
      height: 14px;
      border-radius: 999px;
      background: #e2e8f0;
      overflow: hidden;
    }

    .bar-fill {
      height: 100%;
      background: linear-gradient(90deg, #06b6d4, #0ea5e9);
      border-radius: 999px;
      transition: width 260ms ease;
    }

    input[type="text"] {
      border: 1px solid #cbd5e1;
      border-radius: 9px;
      padding: 7px 10px;
      font-family: inherit;
      font-weight: 500;
      background: #fff;
    }

    input[type="text"]:focus {
      outline: 2px solid #7dd3fc;
      outline-offset: 1px;
      border-color: #38bdf8;
    }

    .chapter-row {
      display: flex;
      flex-wrap: wrap;
      gap: 7px;
      margin: 8px 0 10px;
    }

    .chapter-btn {
      border: 1px solid #99f6e4;
      background: #f0fdfa;
      border-radius: 999px;
      padding: 4px 8px;
      font-size: 0.73rem;
      font-family: inherit;
      font-weight: 700;
      cursor: pointer;
      transition: all 150ms ease;
    }

    .chapter-btn:hover {
      transform: translateY(-1px);
    }

    .chapter-btn.active {
      border-color: #0284c7;
      background: #dbeafe;
      color: #075985;
    }

    .voice-tab {
      position: fixed;
      right: 14px;
      bottom: 14px;
      z-index: 70;
      display: flex;
      align-items: center;
      gap: 8px;
      padding: 10px 12px;
      border: 1px solid #cbd5e1;
      border-radius: 12px;
      background: rgba(255, 255, 255, 0.95);
      box-shadow: 0 8px 20px rgba(15, 23, 42, 0.12);
    }

    @media (max-width: 650px) {
      .wrap {
        width: min(1100px, 94vw);
        padding-top: 14px;
      }
      .voice-tab {
        right: 10px;
        bottom: 10px;
      }
      .hero, .card {
        border-radius: 16px;
      }
    }
  </style>
</head>
<body>
  <main class="wrap">
    <header class="hero">
      <p class="eyebrow">Interactive AI Cheat Sheet</p>
      <h1>LLM Architecture,<br />simplified and visual</h1>
      <p class="subtitle">
        Foundation models are first <strong>pretrained</strong> on broad data, then
        <strong>fine-tuned</strong> for specialized use cases. During generation, the model predicts the
        <strong>next token</strong>, appends it to the sentence, and repeats until completion.
      </p>
    </header>

    <section class="grid">
      <article class="card" style="--i:0;">
        <h2>1) Foundation Pipeline</h2>
        <div class="flow">
          <div class="step">
            <strong>Pretraining</strong>
            Learn language patterns and structure from massive text data.
          </div>
          <div class="step">
            <strong>Foundation Model</strong>
            General base model that can transfer to many tasks.
          </div>
          <div class="step">
            <strong>Fine-tuning</strong>
            Specialize for domains like coding, legal, health, and support.
          </div>
          <div class="step">
            <strong>Production</strong>
            Add guardrails, tools, retrieval, and UX around the model.
          </div>
        </div>
      </article>

      <article class="card" style="--i:1;">
        <h2>2) Model Types</h2>
        <div class="tabs">
          <button class="tab active" data-target="gpt">GPT-style</button>
          <button class="tab" data-target="diffusion">Diffusion</button>
          <button class="tab" data-target="whisper">Whisper-style</button>
        </div>

        <section id="gpt" class="panel active">
          <h3>GPT Models <span class="badge">Text + Reasoning</span></h3>
          <p>Great for writing, coding, Q&A, and multi-step text reasoning.</p>
        </section>
        <section id="diffusion" class="panel">
          <h3>Diffusion Models <span class="badge">Image Generation</span></h3>
          <p>Start from noise and progressively denoise into realistic or stylized images.</p>
        </section>
        <section id="whisper" class="panel">
          <h3>Whisper Models <span class="badge">Audio / Speech</span></h3>
          <p>Convert speech to text for transcription, captions, and multilingual audio tasks.</p>
        </section>
      </article>

      <article class="card" style="--i:2;">
        <h2>3) Parameters (Weights / Coefficients)</h2>
        <p class="mini">
          Parameters, weights, and coefficients refer to the same learned numeric values in the network.
          More parameters usually increase capacity, but also cost and compute.
        </p>
        <div class="scale">
          <div class="row">
            <label for="paramSlider"><strong>Model size:</strong></label>
            <input id="paramSlider" type="range" min="0" max="100" step="1" value="65" />
          </div>
          <p><strong id="paramValue">7B parameters</strong></p>
          <p id="paramHint" class="mini"></p>
        </div>
        <p class="mini">Real models can range from around 1M to nearly 2 trillion parameters.</p>
      </article>

      <article class="card" style="--i:3;">
        <h2>4) Tokenization (Interactive)</h2>
        <p class="mini">
          LLMs do not read full words directly. They read <strong>tokens</strong> (word pieces, punctuation, spaces, symbols).
        </p>
        <div class="token-box">
          <div class="row">
            <label for="tokenMode"><strong>Tokenizer mode:</strong></label>
            <select id="tokenMode">
              <option value="wordpiece">Simple subword style</option>
              <option value="whitespace">Whitespace split</option>
              <option value="character">Character split</option>
            </select>
          </div>
          <p class="mini" style="margin-top:10px;">Try a sentence like: <em>Transformers are awesome for LLMs!</em></p>
          <textarea id="tokenInput">Transformers are awesome for LLMs!</textarea>
          <div id="tokenOutput" class="tokens"></div>
          <div id="tokenStats" class="stats"></div>
        </div>
      </article>

      <article class="card" style="--i:4;">
        <h2>5) Transformers and BERT</h2>
        <p>
          <strong>Transformer</strong>: architecture that uses <strong>attention</strong>, so each token can reference other tokens for context.
        </p>
        <p>
          <strong>BERT</strong>: encoder-style transformer trained with masked words; excellent for understanding tasks like classification and search ranking.
        </p>
      </article>

      <article class="card" style="--i:5;">
        <h2>6) Encoding and Decoding</h2>
        <p class="mini">
          Encoder: convert input into contextual representation. Decoder: predict the next token, append it,
          and repeat token-by-token until the answer ends.
        </p>
        <div class="token-box">
          <div class="pill-row" id="encDecPills">
            <button class="pill active" data-flow="encoder">Encoder flow</button>
            <button class="pill" data-flow="decoder">Decoder flow</button>
            <button class="pill" data-flow="encdec">Encoder-Decoder flow</button>
          </div>
          <div id="encDecFlow" class="flow-mini"></div>
        </div>
      </article>

      <article class="card" style="--i:6;">
        <h2>7) Vectors (Embeddings)</h2>
        <p class="mini">
          Embeddings are numbers with meaning. A token becomes a vector (a list of numbers) and its position
          in an n-dimensional space captures semantic relationships.
        </p>
        <div class="token-box">
          <div class="row">
            <label for="vecA"><strong>Token A:</strong></label>
            <input id="vecA" type="text" value="king" />
            <label for="vecB"><strong>Token B:</strong></label>
            <input id="vecB" type="text" value="queen" />
          </div>
          <div class="vector-grid">
            <div class="vector-box"><strong>A vector</strong><div id="vecOutA"></div></div>
            <div class="vector-box"><strong>B vector</strong><div id="vecOutB"></div></div>
            <div class="vector-box"><strong>Similarity</strong><div id="vecSim"></div></div>
          </div>
          <p class="stats">
            Think 3D for intuition, but real embeddings live in high-dimensional space (for example 768 or 3072 dimensions).
          </p>
        </div>
      </article>

      <article class="card" style="--i:7;">
        <h2>8) How Attention Works</h2>
        <p class="mini">
          Pick a focus token. Bars show attention weights. Across transformer layers, these weights help refine
          how the model understands context before producing the next token.
        </p>
        <div class="token-box">
          <div class="attn-inputs">
            <label for="attnSentence"><strong>Sentence:</strong></label>
            <input id="attnSentence" type="text" value="The robot reads the manual before building the device" style="flex:1;min-width:220px;" />
            <label for="attnFocus"><strong>Focus:</strong></label>
            <select id="attnFocus"></select>
          </div>
          <div id="attnBars" class="attn-bars"></div>
        </div>
      </article>

      <article class="card" style="--i:8;">
        <h2>9) LLM Controls + Applied Concepts</h2>
        <div class="stack">
          <div class="token-box">
            <p class="mini"><strong>Generation Controls</strong>: tune how the model responds.</p>
            <div class="row">
              <label for="tempSlider"><strong>Temperature</strong></label>
              <input id="tempSlider" type="range" min="0" max="2" step="0.1" value="0.7" />
              <strong id="tempValue">0.7</strong>
            </div>
            <div class="row">
              <label for="topPSlider"><strong>Top-p</strong></label>
              <input id="topPSlider" type="range" min="0.1" max="1" step="0.05" value="0.9" />
              <strong id="topPValue">0.9</strong>
            </div>
            <div class="row">
              <label for="maxTokSlider"><strong>Max tokens</strong></label>
              <input id="maxTokSlider" type="range" min="32" max="2048" step="32" value="512" />
              <strong id="maxTokValue">512</strong>
            </div>
            <p class="stats" id="genHint">Balanced output: mostly reliable with some creativity.</p>

            <div class="term-tabs" id="termTabs">
              <button class="term-tab active" data-target="term-temperature">Temperature</button>
              <button class="term-tab" data-target="term-topp">Top-p</button>
              <button class="term-tab" data-target="term-maxtok">Max Tokens</button>
              <button class="term-tab" data-target="term-context">Context</button>
              <button class="term-tab" data-target="term-rag">RAG</button>
              <button class="term-tab" data-target="term-mcp">MCP</button>
              <button class="term-tab" data-target="term-hallucination">Hallucination</button>
            </div>
            <div class="term-tabs">
              <button class="term-tab" data-target="term-prompt">Prompt</button>
              <button class="term-tab" data-target="term-tools">Tools</button>
              <button class="term-tab" data-target="term-agentic">Agentic AI</button>
              <button class="term-tab" data-target="term-datamining">Data Mining</button>
              <button class="term-tab" data-target="term-regurgitation">Regurgitation</button>
            </div>
            <div id="term-temperature" class="term-panel active">Temperature controls randomness. Low values are safer and stable; high values are more creative but can be less factual.</div>
            <div id="term-topp" class="term-panel">Top-p keeps only the most probable token mass and samples from that set. Lower top-p gives tighter answers.</div>
            <div id="term-maxtok" class="term-panel">Max tokens limits response length. Higher limits allow depth but increase latency and cost.</div>
            <div id="term-context" class="term-panel">Context window is how much text the model can consider at once. If key info falls outside it, quality drops.</div>
            <div id="term-rag" class="term-panel">RAG chunks documents, embeds them in vector space, retrieves relevant chunks, and then generates answers grounded in those chunks.</div>
            <div id="term-mcp" class="term-panel">MCP is a protocol for connecting LLMs to external tools, files, and data systems in a consistent way.</div>
            <div id="term-hallucination" class="term-panel">Hallucination is when a model produces confident but incorrect details not grounded in source truth.</div>
            <div id="term-prompt" class="term-panel">A prompt is your instruction package: task, constraints, examples, and format requirements.</div>
            <div id="term-tools" class="term-panel">Tools let the model call external functions like search, APIs, or calculators to perform actions.</div>
            <div id="term-agentic" class="term-panel">Agentic AI can plan steps, use tools, verify outputs, and adapt iteratively toward goals.</div>
            <div id="term-datamining" class="term-panel">Data mining discovers patterns, trends, and anomalies from large datasets for decision-making.</div>
            <div id="term-regurgitation" class="term-panel">Regurgitation is near-verbatim reproduction of memorized text; mitigation includes filtering and policy guardrails.</div>
          </div>

          <div class="token-box">
            <p class="mini"><strong>RAG System Flow</strong>: retrieval first, then grounded generation.</p>
            <div class="flow-mini">
              <div class="step"><strong>1) Chunk Documents</strong>Split source docs into small chunks.</div>
              <div class="step"><strong>2) Embed Chunks</strong>Convert each chunk into an embedding vector.</div>
              <div class="step"><strong>3) Query Embedding</strong>Embed user question in the same vector space.</div>
              <div class="step"><strong>4) Retrieve</strong>Find nearest chunks by vector similarity.</div>
              <div class="step"><strong>5) Augment Prompt</strong>Add top chunks as context for the model.</div>
              <div class="step"><strong>6) Generate</strong>Model predicts next token repeatedly until completion.</div>
            </div>
          </div>

          <div class="chip-grid">
            <div class="chip-card"><strong>Context</strong>The text window the model can currently "see".</div>
            <div class="chip-card"><strong>Prompt</strong>The instruction + examples that steer behavior.</div>
            <div class="chip-card"><strong>Tools</strong>APIs/functions the model can call to act externally.</div>
            <div class="chip-card"><strong>Agentic AI</strong>Model that plans, uses tools, checks results, iterates.</div>
            <div class="chip-card"><strong>MCP</strong>Standard way to connect models to external tools/data sources.</div>
            <div class="chip-card"><strong>RAG</strong>Chunk docs, embed, retrieve nearest chunks, then generate grounded answers.</div>
            <div class="chip-card"><strong>Data Mining</strong>Extract patterns/insights from large datasets.</div>
            <div class="chip-card"><strong>Hallucination</strong>Confident but incorrect output not grounded in truth.</div>
            <div class="chip-card"><strong>Regurgitation</strong>Overly verbatim reproduction from training data.</div>
          </div>
        </div>
      </article>
    </section>
  </main>

  <aside class="voice-tab" aria-label="Voice controls">
    <button class="chapter-btn active" id="voiceToggle" type="button">Voice ON</button>
    <p class="mini" id="voiceInfo" style="margin:0;font-size:0.78rem;">Voice: Indian English</p>
  </aside>

  <script>
    const tabs = document.querySelectorAll(".tab");
    const panels = document.querySelectorAll(".panel");

    tabs.forEach((tab) => {
      tab.addEventListener("click", () => {
        tabs.forEach((t) => t.classList.remove("active"));
        panels.forEach((p) => p.classList.remove("active"));
        tab.classList.add("active");
        const panel = document.getElementById(tab.dataset.target);
        panel.classList.add("active");
      });
    });

    const slider = document.getElementById("paramSlider");
    const paramValue = document.getElementById("paramValue");
    const paramHint = document.getElementById("paramHint");

    function compact(n) {
      if (n >= 1e12) return (n / 1e12).toFixed(2).replace(/\.00$/, "") + "T";
      if (n >= 1e9) return (n / 1e9).toFixed(2).replace(/\.00$/, "") + "B";
      if (n >= 1e6) return (n / 1e6).toFixed(2).replace(/\.00$/, "") + "M";
      return n.toString();
    }

    function hint(n) {
      if (n < 1e8) return "Small model: fast and cheap, limited depth.";
      if (n < 1e10) return "Mid-size model: good quality/cost balance.";
      if (n < 5e11) return "Large model: stronger reasoning, bigger hardware needs.";
      return "Frontier scale: extreme capability, extreme training and inference cost.";
    }

    function sliderToParams(position) {
      const minExp = 6;
      const maxExp = 12.3;
      const exp = minExp + (maxExp - minExp) * (position / 100);
      return Math.round(Math.pow(10, exp));
    }

    function updateParams() {
      const value = sliderToParams(Number(slider.value));
      paramValue.textContent = compact(value) + " parameters";
      paramHint.textContent = hint(value);
    }

    slider.addEventListener("input", updateParams);
    updateParams();

    const tokenInput = document.getElementById("tokenInput");
    const tokenMode = document.getElementById("tokenMode");
    const tokenOutput = document.getElementById("tokenOutput");
    const tokenStats = document.getElementById("tokenStats");

    function tokenizeWhitespace(text) {
      return text.trim() ? text.trim().split(/\s+/) : [];
    }

    function tokenizeCharacter(text) {
      return text ? [...text] : [];
    }

    function tokenizeSubword(text) {
      if (!text.trim()) return [];
      const parts = text.match(/[A-Za-z]+(?:'[A-Za-z]+)?|[0-9]+|[^\w\s]/g) || [];
      const tokens = [];
      parts.forEach((part) => {
        if (/^[A-Za-z]+(?:'[A-Za-z]+)?$/.test(part) && part.length > 6) {
          tokens.push(part.slice(0, 4));
          let rest = part.slice(4);
          while (rest.length > 4) {
            tokens.push("##" + rest.slice(0, 3));
            rest = rest.slice(3);
          }
          if (rest.length) tokens.push("##" + rest);
        } else {
          tokens.push(part);
        }
      });
      return tokens;
    }

    function renderTokens() {
      const text = tokenInput.value;
      const mode = tokenMode.value;
      let tokens = [];

      if (mode === "whitespace") tokens = tokenizeWhitespace(text);
      if (mode === "character") tokens = tokenizeCharacter(text);
      if (mode === "wordpiece") tokens = tokenizeSubword(text);

      tokenOutput.innerHTML = "";
      tokens.forEach((tk) => {
        const chip = document.createElement("span");
        chip.className = "token";
        chip.textContent = tk === " " ? "[space]" : tk;
        tokenOutput.appendChild(chip);
      });

      tokenStats.textContent = "Token count: " + tokens.length;
    }

    tokenInput.addEventListener("input", renderTokens);
    tokenMode.addEventListener("change", renderTokens);
    renderTokens();

    const encDecFlow = document.getElementById("encDecFlow");
    const encDecPills = document.querySelectorAll("#encDecPills .pill");
    const flows = {
      encoder: ["Text Input", "Tokenize", "Embeddings", "Self-Attention", "Context Vectors"],
      decoder: ["Start Token", "Self-Attention", "Predict Next Token", "Append Token", "Repeat"],
      encdec: ["Encode Source", "Cross-Attention", "Decode Step", "Predict Token", "Repeat Until End"]
    };

    function renderEncDec(flowKey) {
      encDecFlow.innerHTML = "";
      flows[flowKey].forEach((step) => {
        const item = document.createElement("div");
        item.className = "step";
        item.innerHTML = "<strong>" + step + "</strong>";
        encDecFlow.appendChild(item);
      });
    }

    encDecPills.forEach((pill) => {
      pill.addEventListener("click", () => {
        encDecPills.forEach((p) => p.classList.remove("active"));
        pill.classList.add("active");
        renderEncDec(pill.dataset.flow);
      });
    });
    renderEncDec("encoder");

    const vecA = document.getElementById("vecA");
    const vecB = document.getElementById("vecB");
    const vecOutA = document.getElementById("vecOutA");
    const vecOutB = document.getElementById("vecOutB");
    const vecSim = document.getElementById("vecSim");

    function fakeEmbedding(word, dims = 8) {
      const v = [];
      let seed = 0;
      for (let i = 0; i < word.length; i++) seed += word.charCodeAt(i) * (i + 1);
      for (let i = 0; i < dims; i++) {
        seed = (seed * 9301 + 49297) % 233280;
        const n = (seed / 233280) * 2 - 1;
        v.push(Number(n.toFixed(3)));
      }
      return v;
    }

    function cosine(a, b) {
      let dot = 0;
      let ma = 0;
      let mb = 0;
      for (let i = 0; i < a.length; i++) {
        dot += a[i] * b[i];
        ma += a[i] * a[i];
        mb += b[i] * b[i];
      }
      return dot / (Math.sqrt(ma) * Math.sqrt(mb) || 1);
    }

    function renderVectors() {
      const a = fakeEmbedding((vecA.value || "token").toLowerCase());
      const b = fakeEmbedding((vecB.value || "token").toLowerCase());
      const sim = cosine(a, b);
      vecOutA.textContent = "[" + a.join(", ") + "]";
      vecOutB.textContent = "[" + b.join(", ") + "]";
      vecSim.textContent = sim.toFixed(3) + (sim > 0.6 ? " (close)" : sim > 0.2 ? " (related-ish)" : " (far)");
    }

    vecA.addEventListener("input", renderVectors);
    vecB.addEventListener("input", renderVectors);
    renderVectors();

    const attnSentence = document.getElementById("attnSentence");
    const attnFocus = document.getElementById("attnFocus");
    const attnBars = document.getElementById("attnBars");

    function wordsFromSentence() {
      return (attnSentence.value.match(/[A-Za-z]+(?:'[A-Za-z]+)?|[0-9]+|[^\w\s]/g) || []);
    }

    function populateFocus(words) {
      attnFocus.innerHTML = "";
      words.forEach((w, i) => {
        const opt = document.createElement("option");
        opt.value = String(i);
        opt.textContent = w + " (" + i + ")";
        attnFocus.appendChild(opt);
      });
    }

    function scoreAttention(words, focusIdx) {
      const f = words[focusIdx] || "";
      const raw = words.map((w, i) => {
        const dist = Math.abs(i - focusIdx);
        let score = 1 / (1 + dist);
        if (w.toLowerCase() === f.toLowerCase()) score += 0.3;
        if (/^[,.!?;:]$/.test(w)) score *= 0.45;
        return score;
      });
      const sum = raw.reduce((a, b) => a + b, 0) || 1;
      return raw.map((v) => v / sum);
    }

    function renderAttention() {
      const words = wordsFromSentence();
      if (!words.length) {
        attnBars.innerHTML = "";
        attnFocus.innerHTML = "";
        return;
      }
      if (attnFocus.options.length !== words.length) populateFocus(words);
      const focusIdx = Number(attnFocus.value || 0);
      const probs = scoreAttention(words, focusIdx);
      attnBars.innerHTML = "";
      probs.forEach((p, i) => {
        const row = document.createElement("div");
        row.className = "bar-row";
        row.innerHTML =
          "<span>" + words[i] + "</span>" +
          "<div class='bar-track'><div class='bar-fill' style='width:" + (p * 100).toFixed(1) + "%'></div></div>" +
          "<span>" + (p * 100).toFixed(1) + "%</span>";
        attnBars.appendChild(row);
      });
    }

    attnSentence.addEventListener("input", () => {
      const words = wordsFromSentence();
      populateFocus(words);
      renderAttention();
    });
    attnFocus.addEventListener("change", renderAttention);
    populateFocus(wordsFromSentence());
    renderAttention();

    const voiceToggle = document.getElementById("voiceToggle");
    const voiceInfo = document.getElementById("voiceInfo");
    const tempSlider = document.getElementById("tempSlider");
    const topPSlider = document.getElementById("topPSlider");
    const maxTokSlider = document.getElementById("maxTokSlider");
    const tempValue = document.getElementById("tempValue");
    const topPValue = document.getElementById("topPValue");
    const maxTokValue = document.getElementById("maxTokValue");
    const genHint = document.getElementById("genHint");
    const termTabs = document.querySelectorAll(".term-tab");
    const termPanels = document.querySelectorAll(".term-panel");

    let voiceEnabled = true;
    let preferredVoice = null;

    function normLang(lang) {
      return (lang || "").toLowerCase().replace("_", "-");
    }

    function scoreVoice(v) {
      const name = (v.name || "").toLowerCase();
      const lang = normLang(v.lang);
      let score = 0;

      if (lang === "en-in") score += 240;
      if (lang.startsWith("en")) score += 80;
      if (lang.endsWith("-in")) score += 40;
      if (/(india|indian)/.test(name)) score += 40;

      // Prefer female voices and penalize likely robotic/system novelty voices.
      if (/(female|woman|samantha|victoria|zira|veena|ava|allison|karen|moira|tessa|serena|natasha)/.test(name)) score += 140;
      if (/(male|man|david|daniel|alex|aaron|fred|raj|ravi|amit|aditya|vivek|rishi|aman|rocko|reed|eddy)/.test(name)) score -= 45;
      if (/(bad news|boing|bubbles|cellos|trinoids|whisper|zarvox|novelty|compact)/.test(name)) score -= 140;

      // Prefer smoother synthesis engines.
      if (/(neural|enhanced|premium|natural|studio|wavenet|ai voice)/.test(name)) score += 130;
      if (/(espeak|festival|mbrola|diphone)/.test(name)) score -= 120;

      return score;
    }

    function pickPreferredVoice() {
      if (!("speechSynthesis" in window)) return null;
      const voices = window.speechSynthesis.getVoices() || [];
      preferredVoice = voices
        .slice()
        .sort((a, b) => scoreVoice(b) - scoreVoice(a))[0] || null;
      if (!preferredVoice && voices.length) {
        preferredVoice = voices[0];
      }
      if (voiceInfo && preferredVoice) {
        voiceInfo.textContent = "Voice: Indian English - " + preferredVoice.name + " (" + preferredVoice.lang + ")";
      }
      return preferredVoice;
    }

    function speakAsAvatar(text) {
      if (!voiceEnabled || !("speechSynthesis" in window) || !text) return;
      window.speechSynthesis.cancel();
      const utter = new SpeechSynthesisUtterance(text);
      utter.rate = 0.86;
      utter.pitch = 1.05;
      utter.volume = 0.92;
      utter.voice = preferredVoice || pickPreferredVoice();
      utter.lang = utter.voice ? utter.voice.lang : "en-IN";
      window.speechSynthesis.speak(utter);
    }

    pickPreferredVoice();
    if ("speechSynthesis" in window) {
      window.speechSynthesis.onvoiceschanged = pickPreferredVoice;
    }

    if (voiceToggle) {
      voiceToggle.addEventListener("click", () => {
        voiceEnabled = !voiceEnabled;
        voiceToggle.textContent = "Voice " + (voiceEnabled ? "ON" : "OFF");
        if (!voiceEnabled && "speechSynthesis" in window) {
          window.speechSynthesis.cancel();
        }
      });
    }

    const tabSpeech = {
      gpt: "GPT models are best for text generation, reasoning, coding help, and question answering.",
      diffusion: "Diffusion models start from noise and gradually form images. They are used for image generation and editing.",
      whisper: "Whisper models convert speech to text and are useful for transcription, captions, and multilingual audio understanding."
    };

    const flowSpeech = {
      encoder: "Encoder flow reads the full input and builds context vectors for understanding tasks.",
      decoder: "Decoder flow predicts one token at a time using prior tokens to continue generation.",
      encdec: "Encoder decoder flow first encodes source input, then decodes output with cross attention to the source."
    };

    const tokenizerSpeech = {
      wordpiece: "Subword tokenization splits long words into meaningful pieces so rare words are still understood.",
      whitespace: "Whitespace split is simple. It breaks text by spaces but loses finer subword detail.",
      character: "Character split treats each character as a token. It is flexible but usually less efficient."
    };

    const termSpeech = {
      "term-temperature": "Temperature controls randomness. Lower temperature gives stable factual style. Higher temperature gives more creativity but more risk.",
      "term-topp": "Top p controls nucleus sampling. The model samples from likely tokens up to a probability mass threshold.",
      "term-maxtok": "Max tokens sets output length budget. Larger values allow deeper answers but use more compute and time.",
      "term-context": "Context window is the memory span of the model for this request.",
      "term-rag": "RAG means chunk, embed, retrieve, then generate. It grounds answers with external evidence before writing.",
      "term-mcp": "MCP is the model context protocol. It standardizes tool and data connections for agents.",
      "term-hallucination": "Hallucination is confident but wrong output, often from missing context or weak grounding.",
      "term-prompt": "Prompt is the instruction design you give the model, including task, constraints, and output format.",
      "term-tools": "Tools allow the model to call external capabilities like APIs, code execution, databases, and search.",
      "term-agentic": "Agentic AI means the model can plan multi step tasks, choose tools, and self check before final output.",
      "term-datamining": "Data mining extracts useful patterns and trends from large data collections.",
      "term-regurgitation": "Regurgitation is when a model repeats memorized text too closely instead of synthesizing safely."
    };

    tabs.forEach((tab) => {
      tab.addEventListener("click", () => {
        const text = tabSpeech[tab.dataset.target];
        if (text) speakAsAvatar(text);
      });
    });

    encDecPills.forEach((pill) => {
      pill.addEventListener("click", () => {
        const text = flowSpeech[pill.dataset.flow];
        if (text) speakAsAvatar(text);
      });
    });

    tokenMode.addEventListener("change", () => {
      const text = tokenizerSpeech[tokenMode.value];
      if (text) speakAsAvatar(text);
    });

    document.querySelectorAll(".step").forEach((el) => {
      el.addEventListener("click", () => speakAsAvatar(el.textContent.trim()));
    });

    slider.addEventListener("change", () => {
      speakAsAvatar("Model size is now " + paramValue.textContent + ". " + paramHint.textContent);
    });

    attnFocus.addEventListener("change", () => {
      const words = wordsFromSentence();
      const focusIdx = Number(attnFocus.value || 0);
      const focusToken = words[focusIdx] || "this token";
      speakAsAvatar("Attention view updated. The model is focusing on " + focusToken + " and distributing weights to related tokens.");
    });

    function generationHint(temp, topP, maxTok) {
      if (temp < 0.4) return "Conservative output: stable and deterministic.";
      if (temp > 1.2) return "Creative output: diverse but higher hallucination risk.";
      if (topP < 0.5) return "Narrow token sampling: focused but less variety.";
      if (maxTok > 1400) return "Long response budget: better depth, higher cost.";
      return "Balanced output: mostly reliable with some creativity.";
    }

    function updateGenerationControls() {
      const t = Number(tempSlider.value);
      const p = Number(topPSlider.value);
      const m = Number(maxTokSlider.value);
      tempValue.textContent = t.toFixed(1);
      topPValue.textContent = p.toFixed(2).replace(/0$/, "");
      maxTokValue.textContent = String(m);
      genHint.textContent = generationHint(t, p, m);
    }

    [tempSlider, topPSlider, maxTokSlider].forEach((el) => {
      el.addEventListener("input", updateGenerationControls);
      el.addEventListener("change", () => {
        speakAsAvatar(
          "Generation controls updated. Temperature " + tempValue.textContent +
          ", top p " + topPValue.textContent +
          ", max tokens " + maxTokValue.textContent +
          ". " + genHint.textContent
        );
      });
    });
    updateGenerationControls();

    [vecA, vecB].forEach((el) => {
      el.addEventListener("change", () => {
        speakAsAvatar("Vector similarity between " + vecA.value + " and " + vecB.value + " is " + vecSim.textContent + ".");
      });
    });

    attnSentence.addEventListener("change", () => {
      speakAsAvatar("Attention sentence updated. Choose focus token to inspect attention weights.");
    });

    tokenInput.addEventListener("change", () => {
      speakAsAvatar("Tokenization updated. Current token count is " + tokenStats.textContent.replace("Token count: ", "") + ".");
    });

    termTabs.forEach((tab) => {
      tab.addEventListener("click", () => {
        termTabs.forEach((t) => t.classList.remove("active"));
        termPanels.forEach((p) => p.classList.remove("active"));
        tab.classList.add("active");
        const panel = document.getElementById(tab.dataset.target);
        if (panel) panel.classList.add("active");
        const speech = termSpeech[tab.dataset.target];
        if (speech) speakAsAvatar(speech);
      });
    });

    document.querySelectorAll(".chip-card").forEach((el) => {
      el.addEventListener("click", () => speakAsAvatar(el.textContent.trim()));
    });

    document.querySelectorAll("article.card h2").forEach((el) => {
      el.addEventListener("click", () => speakAsAvatar(el.textContent.trim()));
    });

    if (!("speechSynthesis" in window) && voiceInfo) {
      voiceInfo.textContent = "Your browser does not support speech synthesis. Try Chrome or Edge.";
    }
  </script>
</body>
</html>
